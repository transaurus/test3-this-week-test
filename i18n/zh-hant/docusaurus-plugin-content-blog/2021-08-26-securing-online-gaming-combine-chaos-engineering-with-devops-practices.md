---
slug: /Securing-Online-Gaming-Combine-Chaos-Engineering-with-DevOps-Practices
title: 'Securing Online Gaming: Combine Chaos Engineering with DevOps Practices'
authors: zhaojunwu
image: /img/blog/chaos-mesh-tencent-ieg.jpeg
tags: [Chaos Mesh, Chaos Engineering, Use Cases]
---

![確保線上遊戲安全：結合混亂工程與 DevOps 實踐](/img/blog/chaos-mesh-tencent-ieg.jpeg)

互動娛樂事業群（IEG）是騰訊控股旗下專注於開發線上視頻遊戲及其他數位內容（如直播）的部門，以發行多款熱門遊戲而聞名。

<!--truncate-->

本文將說明我們為何及如何將混亂工程引入 DevOps 流程。

我們每日處理超過 1000 萬次總訪問量，尖峰時段每秒查詢量（QPS）超過 100 萬次。為確保玩家享有流暢體驗，我們推出各種日常或季節性遊戲活動，有時單日活動程式碼更新超過 500 次。隨著用戶基數增長，資料總量快速攀升至 200 TB。我們必須管理龐大用戶查詢與快速迭代發布，並成功實現此目標。

雲原生 DevOps 方案使活動運營者擺脫日益增多的線上活動。我們開發的流水線涵蓋從編寫程式碼到生產環境部署的全流程：一旦偵測到新活動程式碼，運維平台會自動構建映像並部署至騰訊雲容器服務（TKE）。整個自動化流程僅需 5 分鐘。

目前 IEG 幾乎所有運維服務皆運行於 TKE。雲原生技術的彈性伸縮能力實現更快速的雲服務擴容與縮容。

此外，我們期望迭代更簡便。最佳實踐是將龐大難維護的服務拆解為多個可獨立維護的「小型」服務。小型服務程式碼量少、邏輯簡單，降低交接與培訓成本。我們開發者持續實踐此微服務架構作為 DevOps 倡議，但挑戰依然存在：服務數量增加時，服務間調用複雜度隨之提升。**更糟的是，若某個「小型」服務故障，可能引發連鎖反應導致全服務崩潰——形成微服務依賴地獄。**

問題在於各服務的容錯能力參差不齊：部分支援降級，部分則否；某些服務無法及時告警或缺乏有效除錯工具，導致服務除錯成為日常工作中日益棘手的難題。

但我們不能放任不管。若系統不穩定持續流失玩家怎麼辦？若發生災難性故障怎麼辦？

## 引入故障測試

Netflix 提出混亂工程概念：透過在非生產環境注入故障，測試系統對邊緣案例的韌性以達成理想可靠性。根據 Gartner 報告，預計 2023 年將有 40% 企業採用混亂工程實現 DevOps 目標，減少 20% 非計劃性停機時間。

這正是我們規避最糟情境的方法。我認為故障注入現已成為技術團隊的必要實踐。早期測試中，開發者會在服務上線前關閉節點，驗證主節點是否自動切換至備援節點及災備機制是否生效。

**但混亂工程不僅是故障注入**，更是不斷推動新技術、專業測試工具與嚴謹理論的領域，因此我們持續探索。

IEG 於一年多前正式啟動混亂工程專案。首次執行即追求完善，關鍵在於選擇支援 Kubernetes 環境實驗的混亂工程工具。**經審慎評估，我們認為 [Chaos Mesh](https://github.com/chaos-mesh/chaos-mesh) 是最佳選擇**，原因如下：

- 作為雲原生計算基金會（CNCF）沙盒專案，擁有活躍且高效的社群。

- 無需侵入現有應用程式。

- 它提供網頁介面及多種故障注入類型，如下圖所示。

![混沌工程工具比較圖](/img/blog/comparison-of-chaos-engineering-tools.png)

> 注意：此比較已過時，僅旨在對比 Chaos Mesh 與其他知名混沌工程平台支援的故障注入功能，並非為推崇或定位特定專案。歡迎指正任何內容。

## 建構混沌測試平台

我們的混沌工程團隊將 Chaos Mesh 嵌入持續整合與持續交付流程。如下圖所示，Chaos Mesh 在營運平台中扮演關鍵角色：透過其儀表板 API 建立、執行、刪除混沌實驗，並在自有平台監控。可模擬 Pod、容器、網路及 I/O 的基礎系統層級故障。

![Chaos Mesh 嵌入 IEG 營運平台示意圖](/img/blog/chaos-mesh-embedded-in-IEG's-operation-platform.png)

在 IEG，**混沌工程實踐可歸納為包含數個關鍵階段的閉環流程**：

- 提升系統整體韌性

  建構可隨需求調整的混沌測試平台。

- 設計測試計畫

  需明確定義目標、範圍、注入故障類型、監控指標等，確保測試過程受控。

- 執行混沌實驗並檢視結果

  比對系統在混沌實驗前後的效能表現。

- 解決潛在問題

  修復發現的缺陷並升級系統，供後續實驗使用。

- 重複驗證效能

  反覆執行混沌實驗確認系統表現是否符合預期。達標後即可設計新測試計畫。

![IEG 混沌工程五階段流程圖](/img/blog/five-phases-of-chaos-engineering-in-IEG.png)

以**高 CPU 負載下的服務效能測試**為例：先編排調度實驗，執行後透過營運平台即時監控相關服務的多項指標（如每秒查詢次數(QPS)、延遲、回應成功率）。平台自動生成報告供檢視，確認實驗是否達成預期目標。

## 應用案例

以下列舉 DevOps 流程中應用混沌工程的實例。

### 精細化故障注入

無須癱瘓整個系統即可驗證遊戲可用性。例如僅對單一遊戲帳號注入網路延遲故障，觀察其反應。我們透過流量劫持技術在閘道層實現此精細化實驗。

### 紅隊演練

例行混沌實驗易使團隊成員感到乏味——這好比要求左手打右手。**IEG 將紅隊演練整合至混沌工程，促使系統韌性有機成長**。紅隊演練類似滲透測試但更具針對性：模擬外部攻擊者視角進行突襲測試。若由維運團隊主導，會對特定服務製造故障，檢驗開發團隊的應對表現；發現潛在缺陷時將啟動「嚴肅談話」。反之，開發團隊會主動執行混沌實驗，預先排除風險避免究責。

![IEG 紅隊演練流程圖](/img/blog/red-teaming-process-in-IEG.png)

### 依賴分析

對於微服務而言，管理依賴關係至關重要。在我們的案例中，非核心服務絕不能成為核心服務的瓶頸。所幸透過混沌工程，我們只需在調用服務中注入故障並觀察主要服務受到的影響程度，即可輕鬆執行依賴分析。根據結果，我們能在特定情境下優化服務調用鏈。

### 自動化故障檢測與診斷

我們也正在探索利用AI機器人協助檢測和診斷故障。隨著服務日益複雜，發生故障的可能性也隨之增加。**我們的目標是透過在生產環境或其他受控環境中進行大規模混沌實驗，訓練出故障檢測模型。**

## 混沌工程賦能DevOps實踐

目前平均每週有超過50人執行混沌實驗，運行超過150次測試，總計發現逾100個問題。

過去需要手寫腳本才能執行故障注入的日子已一去不復返，這對不熟悉的人來說曾是艱鉅任務。**將混沌工程與DevOps實踐相結合的優勢顯而易見：只需幾分鐘，透過簡單拖放即可編排各類故障類型，一鍵執行並在單一平台中即時監控結果。**

![Chaos engineering with DevOps ensures efficient fault injection](/img/blog/chaos-engineering-with-devops.png)

得益於功能完備的混沌工程工具和精簡化的DevOps流程，我們估計過去半年間IEG的故障注入效率與基於混沌的優化至少提升了10倍。若您對業務中實施混沌工程仍有疑慮，希望我們的經驗能提供些許幫助。